---
title: "Homework 5 R markdown"
author: "(your name here)"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  word_document:
    fig_height: 4
    fig_width: 4.5
---


```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
#trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

#### <span style="color:Blue">**Intellectual Property:**</span>  
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.

#### <span style="color:Crimson">**Due Date:**</span>  
Tuesday, October 10, 2017 at 11:59 PM 

***  
***  

##########################################################################
## Problem 1: Identifying Methods
##########################################################################

<span style="color:DarkViolet">Using the data in the Trees.csv file, fit the response Volume on the remaining variables, find coefficient estimates for the model  
$Volume = \beta_0 + \beta_1 Girth + \beta_2 Height + \beta_3 GirthHeight + \beta_4 Girth2 +\beta_5 Girth2Height$  
using each of the following methods:  
1.  Multiple linear regression  
2.  Ridge Regression ($\alpha$  = 0), with $\lambda$ = 0.01, 0.02, …, 0.99, 1.00.  
3.  LASSO ($\alpha$ = 1), with $\lambda$ = 0.01, 0.02, …, 0.99, 1.00.  
4.  Elastic net, with $\alpha$  = 0.7 and $\lambda$ = 0.01, 0.02, …, 0.99, 1.00. </span>


```{r}
  #read in the data
trees = read.csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 5/Trees.csv")[,-1]
  #fit the multiple linear regression model
fit = lm(Volume~.,data = trees)
  #check summary
summary(fit)

```




#####################################
### <span style="color:DarkViolet">Question 1</span> **<span style="color:Crimson">(1 point)</span>**:
#####################################

<span style="color:DarkViolet">Consider the fit of model 1., multiple linear regression. How many of the predictors are marginally significant (after fitting the other predictors)?</span>  

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
0,  <-- Correct Answer
1,  
2,  
3,  
4

#####################################
### <span style="color:DarkViolet">Question 2</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">Provide an explanation for the answer to the previous question. </span>



The reason none of the predictors are significant is because of collinearity - many of the predictors in this data set are strongly correlated because they composed of each other. 



<span style="color:green">**Text Answer**: </span>

#####################################
### <span style="color:DarkViolet">Question 3</span> **<span style="color:Crimson">( points)</span>**:
#####################################

<span style="color:DarkViolet">Which of the following methods could **NOT** have produced the below coefficients? Select all methods that apply.  
$\hat{\beta}_0$ = −5.90695, $\hat{\beta}_1$ = 0, $\hat{\beta}_2$ = 0, $\hat{\beta}_3$ = 0.01194, $\hat{\beta}_4$ = 0.03991, $\hat{\beta}_5$ = 0.00115</span>  

<span style="color:green">**Multiple SELECT Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  
Multiple linear regression,  <--correct
Ridge Regression,  <--correct
Elastic net,  
LASSO  

***

#####################################
### <span style="color:DarkViolet">Question 4-9</span> **<span style="color:Crimson">(6 points, 1 each)</span>**:
#####################################

<span style="color:DarkViolet">Input the values for the coefficients of the LASSO model fit with $\lambda$ = 0.1. Please use the values  
$\texttt{lambdalist = c((1:100)/100)}$  
for fitting with the glmnet() function.</span>  

<span style="color:DarkViolet">$\hat{\beta}_0$ =  
$\hat{\beta}_1$ =   
$\hat{\beta}_2$ =   
$\hat{\beta}_3$ =   
$\hat{\beta}_4$ =   
$\hat{\beta}_5$ = </span>    

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
library(glmnet)
  #setting up the list of lambda values
lambdalist = sort(c((1:100)/100),decreasing = T)
  #pull volume as y
y = trees[,1]
  #pull the remaining variables into a matrix as the x's.
x = model.matrix(Volume~.,data = trees)[,-1]
  #fit the LASSO regression
LRfit = glmnet(x, y, alpha = 1, lambda = lambdalist)
  #pull the coefficients 
coef(LRfit,s=0.1)

```

***

#####################################
### <span style="color:DarkViolet">Question 10</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">The image shows a plot of the $CV_{(5)}$ values for the Ridge Regression, LASSO, and Elastic net models, plotted against the value of $\lambda$.  Which model is optimal?</span>

[See D2L Homework 5 for image, not able to include in code.]  

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
Elastic net,  
Ridge Regression,  
Multiple linear regression,  
LASSO



#####################################
### <span style="color:DarkViolet">Question 11</span> **<span style="color:Crimson">(1 point)</span>**:
#####################################

<span style="color:DarkViolet">The model you chose in the previous question is optimal with $\lambda \approx$</span>  

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  




***
***

##########################################################################
## Problem 2:  Motivation for Penalized Regression
##########################################################################

<span style="color:DarkViolet">For the **College** data set from the **ISLR** package, we will work to predict *log.Enroll*, the natural log transformation of *Enroll*, the number of new students enrolled (per year) as a function of the other variables.  You may use the $\texttt{help(College)}$ command to learn more about the dataset. </span>


***

#####################################
### <span style="color:DarkViolet">Question 12</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">Each of the five variables *Enroll, Apps, Accept, F.Undergrad*, and *P.Undergrad* is related to the size of the college and has strongly right-skewed distribution.  Explain why the skewness makes sense, in terms of the variety of colleges covered in this dataset. </span>


Upon looking at a summary of the dataset, more than 70% of the colleges listed are private, which always typically have a lower number of students and enrollments (mainly due to cost factors). Therefore it would make since that the majority of a histogram on these variables would "bunch up" toward the left, but have a right-skew (which are most likely the public schools).

```{r}
library(ISLR)
data("College")

help("College")
summary(College)
```




<span style="color:green">**Text Answer**: </span>


#####################################
### <span style="color:DarkViolet">Question 13</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">To make linear relationships more reasonable, log transformation of these five variables work well. Define the new variables *log.Enroll, log.Apps, log.Accept, log.F.Undergrad*, and *log.P.Undergrad* as the (natural) log transformation of the corresponding variables.  Add these variables to the data frame.  Submit an appropriate plot for describing the distribution of the response, *log.Enroll*, to **Homework 5: Distribution of response** discussion. </span>

<span style="color:green">**Graph Answer**  </span>: 
  (post to discussion board on D2L)
```{r,echo=FALSE}
  #adding log transformed versions of these skewed variables.
College$log.Enroll = log(College$Enroll)
College$log.Apps = log(College$Apps)
College$log.Accept = log(College$Accept)
College$log.F.Undergrad = log(College$F.Undergrad)
College$log.P.Undergrad = log(College$P.Undergrad)

  #create a histogram of log enrollments.
hist(College$log.Enroll, main = "Distribution of College Enrollments", xlab = "Number of Enrollments (log scale)")
```


#####################################
### <span style="color:DarkViolet">Question 14</span> **<span style="color:Crimson">(1 point)</span>**:
#####################################

<span style="color:DarkViolet">Which of the following predictors is most highly correlated with the response *log.Enroll*</span>?

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
Expend,  
log.Accept,  <----
log.P.Undergrad,  
perc.alumni,  
Personal


```{r}
  #find the correlation between the response and the predictors listed. Want abs() to find the most "strongly" correlated.
abs(cor(College$log.Enroll,College[,c("Expend","log.Accept","log.P.Undergrad","perc.alumni","Personal")]))

```
 


#####################################
### <span style="color:DarkViolet">Question 15</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">Provide a reason that the predictor you chose in the previous question makes sense, based on the description of the data. </span>

<span style="color:green">**Text Answer**: </span>

The reason enrollment is correlated with acceptance is because these are two measurements that relate to a process. You must first be accepted to the college, and then you can enroll in courses. There may be some potential students that are accepted to the college, but in fact select a different college in their selection process, therefore they never enroll at that particular university. 

#####################################
### <span style="color:DarkViolet">Question 16</span> **<span style="color:Crimson">(3 points)</span>**:
#####################################

<span style="color:DarkViolet">Describe features of this data set that support using a penalized regression model (versus a basic multiple linear regression model). </span>

<span style="color:green">**Text Answer**: </span>


When looking at a larger correlation matrix, there are many variables within this dataset that tend to be strongly correlated with each other. This can introduce the problem of collinearity, and therefore a penalized regression model can be used to either penalize and shrink some of the terms (or remove them altogether like in the LASSO or Elastic Net).

```{r}
cor(College[,-1])

```

***
***

##########################################################################
## Problem 3:  Applying Methods
##########################################################################

<span style="color:DarkViolet">Using the data **College** data set from the **ISLR** package, with the new variables as defined in Problem 2, fit the response *log.Enroll* on the remaining variables:  *Private, Top10perc, Top25perc, Outstate, Room.Board, Books, Personal, PhD, Terminal, S.F.Ratio, perc.alumni, Expend, Grad.Rate, log.Apps, log.Accept, log.F.Undergrad, log.P.Undergrad*.  </span>

***

<span style="color:DarkViolet">For the following questions 17-20,  fit the LASSO ($\alpha$ = 1) model and find coefficients for $\lambda$ = 0.001, 0.002, …, 0.999, 1.000.  Determine how many coefficients are non-zero, **excluding the intercept**.</span>

```{r echo=FALSE, eval=FALSE}
library(glmnet)
  #extract y as the log.enroll
y = College[,19]
  #extract all the remaining variables as the x's.
x = model.matrix(log.Enroll~.-Enroll-Apps-Accept-F.Undergrad-P.Undergrad,data = College)[,-1]
  #setting up a list of lambda values in desc order
lambdalist = seq(1,0.001, by = -0.001)
  #fitting the LASSO model.
LRfit = glmnet(x,y,alpha = 1,lambda = lambdalist)

  #checking coefficients at different constraint values. 
coef(LRfit,s=0.02)

coef(LRfit,s=0.03)

coef(LRfit,s=0.05)

coef(LRfit,s=0.08)

```

#####################################
#### <span style="color:DarkViolet">Question 17-20</span> **<span style="color:Crimson">(4 points, 1 each)</span>**:
#####################################

17.  For the LASSO model with $\lambda$ = 0.02, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3, 
4,  <--- correct
5

18.  For the LASSO model with $\lambda$ = 0.03, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3,  <--- correct
4,  
5   

19.  For the LASSO model with $\lambda$ = 0.05, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  <---- correct
3,  
4,  
5

20.  For the LASSO model with $\lambda$ = 0.8, how many coefficients are non-zero?  
<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
1,  
2,  
3,  <--- correct
4,  
5



#####################################
#### <span style="color:DarkViolet">Question 21</span> **<span style="color:Crimson">(4 points)</span>**:
#####################################
<span style="color:DarkViolet">Which variable(s) appear to be the most useful for predicting *log.Enroll* with the LASSO model? Select all that apply.</span>

<span style="color:green">**Multiple SELECT Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  
Private,  
Top10perc,  
Top25perc,  
Outstate,  
Room.Board,  
Books,  
Personal,  
PhD,  
Terminal,  
S.F.Ratio,  
perc.alumni,  
Expend,  
Grad.Rate,  
log.Apps,  
log.Accept,         <--- correct
log.F.Undergrad,    <--- correct
log.P.Undergrad

***

<span style="color:DarkViolet">For the following questions, use the Elastic net model, with$\alpha$ = 0.75 and $\lambda$  = 0.001, 0.002, …, 0.999, 1.000.</span>



#####################################
### <span style="color:DarkViolet">Question 22</span> **<span style="color:Crimson">(3 points)</span>**:
#####################################


<span style="color:DarkViolet">Setting a seed of 5, make groups for 10-fold cross-validation:  
$\texttt{groups = c(rep(1:10,77),(1:7))}$  
$\texttt{set.seed(5, sample.kind = "Rounding")}$  
$\texttt{cvgroups = sample(groups,777)}$  
Use the $\texttt{cv.glmnet}$ command along with these cross-validation groups to perform crossvalidation,
with $CV_{(10)}$ contained in the value cvm of the output. For the Elastic net model
with $\alpha$ = 0.75, make a plot of $CV_{(10)}$ vs $\lambda$ and submit your plot to **Homework 5: Elastic net model plot**.
</span>

<span style="color:green">**Graph Answer**</span>: 
  (post to discussion board on D2L)
```{r,echo=FALSE}
  #load the glmnet library
library(glmnet)

  #set seed for reproducibility
set.seed(5, sample.kind = "Rounding")

  #create groups of 10 folds, with remainder 1 through 7
groups = c(rep(1:10,77),(1:7))

  #randomize the groups without replacement.
cvgroups = sample(groups,777)

  #set number of cross validation folds
k = 10

  #set sample size
n = nrow(College)

  #create a vector of lambda's between 0.001 to 1, by 0.001 increments. Ordered greatest to least.
lambdalist = seq(1,.001, by=-0.001)

  #fit the elastic net regression model
cvENfit = cv.glmnet(x, y, alpha = 0.75, lambda = lambdalist, nfolds=k, foldid=cvgroups)

plot(lambdalist,cvENfit$cvm, main = "10-fold Cross Validation Error vs. Lambda", xlab = "Lambda", ylab = "CV Error")



cvENfit$lambda.min
min(cvENfit$cvm)
```

#####################################
### <span style="color:DarkViolet">Question 23</span> **<span style="color:Crimson">(2 points)</span>**:
#####################################

<span style="color:DarkViolet">For the Elastic net model with $\alpha$ = 0.75, what is the value of $\lambda$ that minimizes $CV_{(10)}$?</span>

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
  #find the minimum CV error rate based on all the different lambda values.
min(cvENfit$cvm)
  #order the CV error rates by lowest to greatest, and find the indice where its the lowest
whichlowestcvEN = order(cvENfit$cvm)[1]
  #use that indicie to find the lambda value.
bestlambdaEN = lambdalist[whichlowestcvEN]
bestlambdaEN

```


#####################################
### <span style="color:DarkViolet">Question 24</span> **<span style="color:Crimson">(3 points)</span>**:
#####################################

<span style="color:DarkViolet">Enter your R code below for computing the $CV_{(10)}$ measure for the Elastic net model with $\alpha$ = 0.75. </span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
  #load the glmnet library
library(glmnet)

  #set seed for reproducibility
set.seed(5, sample.kind = "Rounding")

  #create groups of 10 folds, with remainder 1 through 7
groups = c(rep(1:10,77),(1:7))

  #randomize the groups without replacement.
cvgroups = sample(groups,777)

  #set number of cross validation folds
k = 10

  #create a vector of lambda's in desc order.
lambdalist = seq(1,.001, by=-0.001)

  #fit the elastic net regression model
cvENfit = cv.glmnet(x, y, alpha = 0.75, lambda = lambdalist, nfolds=k, foldid=cvgroups)
```
