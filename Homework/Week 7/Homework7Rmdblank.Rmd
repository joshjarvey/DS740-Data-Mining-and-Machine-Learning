---
title: "Homework 7 R markdown"
author: "Josh Jarvey"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  word_document:
    fig_height: 4
    fig_width: 4.5
---


```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
#trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

#### <span style="color:Blue">**Intellectual Property:**</span>  
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.

#### <span style="color:Crimson">**Due Date:**</span>  


***  
***  

##########################################################################
## Problem 1: Analyze Variables with Decision Trees
##########################################################################

In this problem, you will use decision trees to analyze the variables associated with which brand of orange juice customers choose to purchase.

Data Set: Load the OJ data set, which is in the ISLR package.

#####################################
### Question 1 (1 point) 

After loading the OJ data set, set the random seed equal to 7, using:
   set.seed(7, sample.kind = "Rounding")
and take a random sample of 800 rows of the data. This will be the training data set; the remaining observations will be the validation set.

Enter your R code below.

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
  #load the data set.
library(ISLR)
data("OJ")

  #set seed for reproducability. 
set.seed(7, sample.kind = "Rounding")

  #using a vector of size 1:1070, select 800 numbers without replacement. These are our indices that we'll use for the OJ set when training our model. We can use OJ "-train" when testing our model.
train = sample(1:nrow(OJ),800,replace = F)
```


#####################################
### Question 2 (2 points) 

Fit a tree to the training data, using Purchase as the response variable and all other variables as predictors.  Which variables were used in constructing the tree?  Select all that apply.

<span style="color:green">**Multiple SELECT Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  

	
LoyalCH <<--- correct

	
Store

	
PriceDiff <<--- correct

	
SalePriceMM <<--- correct

	
PriceCH


#####################################
### Question 3 (2 points) 

What is the error rate on the training set?   <<---  0.1788

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
library(tree)
  #fit the tree, using train data only.
fitTree = tree(Purchase~.,data = OJ[train,])
  #find the misclassification rate
summary(fitTree)
```


***

#####################################
### Question 4 (4 points)

Plot the decision tree with category labels.  Submit your plot to the Homework 7: Decision tree discussion board.  With your plot, write 3-5 sentences describing the model.

[You don't need to enter anything here.  Make sure you submit your plot and description to the discussion board.]

<span style="color:green">**Graph Answer**  </span>: 
  (post to discussion board on D2L)
```{r,echo=FALSE}
plot(fitTree)
text(fitTree,pretty = 0)

```

Based on the plot, it appears that brand loyalty is one of the biggest deciding factors when choosing between Citrus Hill or Minute Maid orange juice. In fact, the "Loyalty" variable is the root node (most important), and its split is approximately "half way down the middle", where if you are loyal to Minute Maid (indicated by <~0.48), then you're more likely to purchase MM, otherwise if you're more loyal to Citrus Hill (>~0.48), you're more likely to purchase CH. The only other deciding factor in this deals with the price difference between MM and CH. If you're loyal to CH is measured >~0.48 but <~0.76, and MM is 0.16$ cheaper, then MM is purchased. Seems like MM fans are loyal, whereas so are Citrus Hill (unless the price is right).


#####################################
### Question 5 (2 points)

Compute the confusion matrix for the validation set.  What is the validation set error rate?

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
  #complete the prediction using the test set.
predprob = predict(fitTree,OJ[-train,], type = "class")
  #create a confusion matrix of the test set.
table(predprob,OJ$Purchase[-train])

(18+21)/(18+21+147+84)
```

answer: 0.1444444


#####################################
### Question 6 (2 points)

Use 10-fold cross-validation on the training data to choose the number of leaves that minimizes the classification error rate.  What are the optimal numbers of leaves? Select all that apply.

```{r,echo=FALSE}
  #complete CV10 on the tree model
cvTreeFit = cv.tree(fitTree, FUN = prune.misclass)
  #review the results - it appears leaves 8 and 5 provide the lowest CV10 score. 
cvTreeFit

```


<span style="color:green">**Multiple SELECT Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  
1
	
2

3

4

5 <<-- correct

6

7

8 <<---- correct


#####################################
### Question 7 (1 point) 

Create a pruned tree with 5 leaves.  What is the error rate of the pruned tree on the validation set?

<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  

```{r,echo=FALSE}
  #create a tree within the prune.misclass() function. This new tree uses "test" data, and keeps it to 5 best leaves. 
prunedFitTree = prune.misclass(tree(Purchase~.,data = OJ[-train,]), best = 5)
  #check misclassification error. 
summary(prunedFitTree)
```

answer: 0.1148


***

##########################################################################
## Problem 2: Use Boosting to Predict Salaries
##########################################################################

In this problem, you will use boosting to predict the salaries of baseball players.

Data Set: Load the Hitters data set; it's in the ISLR package.

#####################################
### Question 8 (2 points) 

After loading the Hitters data set, remove the observations with unknown salary, and then log-transform the salaries.  

Enter your R code below.

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
library(ISLR)
data("Hitters")
  #remove NA's
Hitters = na.omit(Hitters)
  #add a log() transformed version of the salary 
Hitters$logSalary = log(Hitters$Salary)
```

#####################################
### Question 9 (1 point) 

Perform boosting to predict log(Salary) in terms of the other variables in the data set (excluding Salary).  Use:

* 5000 trees,  
* a shrinkage parameter of .001, and  
* an interaction depth of 4.  

```{r}
library(gbm)

boostFit = gbm(logSalary~.-Salary, data = Hitters, n.trees = 5000, shrinkage = 0.001, interaction.depth = 4, distribution = "gaussian")

summary(boostFit)

```

Which of the variables is most important for predicting log(Salary) in this model?

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  

	
CAtBat  <<-- correct.

HmRun

CRuns

Years

#####################################
### Question 10 (4 points) 

Set the random seed to 7, using:
   set.seed(7, sample.kind = "Rounding") 
and perform 10-fold cross-validation to compare boosting (using the same parameters as in the previous question) to multiple linear regression. 

Enter your R code below.


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
  #set seed for reproduceability
set.seed(7, sample.kind = "Rounding") 
  #count the sample size.
n = nrow(Hitters)
  #set the number of folds.
k = 10
  #create groups of 1-10 for the entire dataset
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k)) 

  #randomly shuffle the 1-10 dataset.
cvgroups = sample(groups,n)

  #creating an empty vector to store predicted values.
allpredictedCVLM = rep(0,n)
allpredictedCVBoost = rep(0,n)


for (i in 1:k){
    #setting test set equal to the current i'th fold.
  test = (cvgroups == i)
    #fit the linear model on the training data
  fitLM = lm(logSalary~.-Salary, data = Hitters,subset=!test)
    #use the test set to generate predictions.
  allpredictedCVLM[test] = predict.lm(fitLM,Hitters[test,])
    
    #fit the boosted model on the training data.
  boostFit = gbm(logSalary~.-Salary, data = Hitters[!test,], 
                 n.trees = 5000, 
                 shrinkage = 0.001, 
                 interaction.depth = 4, 
                 distribution = "gaussian")
  
    #use the test set to generate predictions. 
  allpredictedCVBoost[test] = predict(boostFit, newdata = Hitters[test,],n.trees = 5000)
}

  #calculate MSE for both models.
sum((allpredictedCVLM-Hitters$logSalary)^2)/n
sum((allpredictedCVBoost-Hitters$logSalary)^2)/n
```


***

What MSE do you find for each method?

#####################################
### Question 11 (1 point) 

Boosting:0.4319816


<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
```


#####################################
### Question 12 (1 point) 

Linear regression: 0.2213834


<span style="color:green">**Numeric Answer**  </span> 
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
```{r,echo=FALSE}
```


#####################################
### Question 13 (1 point) 

Which model has the lower cross-validation MSE for this data set?

<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  

Boosting <<---- correct

Linear regression


***


##########################################################################
## Problem  3: Analyzing Salaries Through Bagging and Random Forests
##########################################################################

In this problem, you will continue your analysis of the salaries of baseball players using bagging and random forests.

Data Set: Continue to use the Hitters data set.

#####################################
### Question 14 (2 points)

Use $\texttt{?Hitters}$ to view what each variable in the data set represents.  Examine some preliminary graphs and summaries of the data.  If we want to use decision trees to analyze this data set, why are random forests a good idea? Explain in 2-4 sentences.


When we take a look at the dataset, we notice a high degree of correlation between predictor variables, thus leading to issues of multicollinearity. Certain pairs of variables may dominate in the model, which will cause high variance and may cause the issue of overfitting. Random forest attempts to solve this by not only pick random observations during its model fitting process (bagging), but also selecting the predictors to use at random. This creates many trees with different predictors at its root node, thus making a more robust model against collinearity.  


```{r}
summary(Hitters)

library(car)

vif(fitLM)
```


<span style="color:green">**Text Answer**: </span>


#####################################
### Question 15 (1 point)

Perform bagging to predict log(Salary) in terms of the other variables in the data set (excluding Salary).  

Enter your R code below.

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
library(randomForest)

  #Note: a random forest with maximum variables is just a normal bagged forest (its not randomly excluding predictors when mtry=total predictors).
hittersBagging = randomForest(logSalary~.-Salary, data = Hitters,
                              mtry = 19, importance=TRUE)


fitlmfull = lm(formula = logSalary ~ . - Salary, data = Hitters)
hittersBagging
summary(fitlmfull)
```

#####################################
### Question 16 (1 point) 

Examining the bagged model you created in the previous question, how does the proportion of variation explained by the bagged model compare with the proportion of variation explained by multiple linear regression?


The proportion of variation explained by the bagged model (76.01%) is much greater than that of the normal linear model (55.86%). Therefore it appears to be the better model. 

<span style="color:green">**Text Answer**: </span>


#####################################
### Question 17 (1 point) 
Which variable is more important for predicting log(Salary) in the bagged model?

```{r}
  #when looking at these column headers:
    #%IncMSE = this is the % of increase in MSE when you *DON'T* include this variable in your model
    #IncNodePurity = this is the increase in node purity when including this variable in your model
importance(hittersBagging)
varImpPlot(hittersBagging)
```


<span style="color:green">**Multiple choice Answer** </span>
  **<span style="color:red">(AUTOGRADED on D2L)</span>**:  one of  
	
CRBI <--- correct???

Years

#####################################
### Question 18 (2 points)

Set the random seed to 7 again, using:
   set.seed(7, sample.kind = "Rounding")
and use 10-fold cross-validation to compare bagging with random forests using 6 variables.  Write 1-2 sentences comparing the MSE of each of these methods to the MSE of boosting found in Problem 2.


Random Forest bagging = ~0.0326
Boosting = ~0.2213834

The CV10 error for the random forest is much less (~0.0326) compared to the CV10 error from the boosting process (~0.2213). This is due to the fact that there is collinearity between variables within the dataset, which the random forest is better equipped to handle being that it selects a subset of random predictors during its tree building process.  

<span style="color:green">**Text Answer**: </span>


```{r}
  #set seed for reproduceability
set.seed(7, sample.kind = "Rounding") 
  #count the sample size.
n = nrow(Hitters)
  #set the number of folds.
k = 10
  #create groups of 1-10 for the entire dataset
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k)) 

  #randomly shuffle the 1-10 dataset.
cvgroups = sample(groups,n)

  #creating an empty vector to store predicted values.
allpredictedCVRF = rep(0,n)


for (i in 1:k){
    #setting test set equal to the current i'th fold.
  test = (cvgroups == i)
    #fit the random forest to the data. We use 6 variables for each tree built in the random forest, because P/3 is a good rule of thumb for regression problems. 
  hittersBagging6 = randomForest(logSalary~.-Salary,data = Hitters, mtry = 6, importance=TRUE)

    #use the test set to generate predictions. 
  allpredictedCVRF[test] = predict(hittersBagging6, newdata = Hitters[test,])
}

  #calculate MSE for both models. = ~0.0326
sum((allpredictedCVRF-Hitters$logSalary)^2)/n


```






