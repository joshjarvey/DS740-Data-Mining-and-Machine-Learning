---
title: "Homework 3 R markdown"
author: "Josh"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  word_document:
    fig_height: 4
    fig_width: 4.5
---


```{r, setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
#trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

#### <span style="color:Blue">**Intellectual Property:**</span>  
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.

#### <span style="color:Crimson">**Due Date:**</span>  
Tuesday, Sep 26, 2017 at 11:59 PM 

***  

#####################################################
## <span style="color:DarkViolet">Problem 1:  Linear Regression  </span>
#####################################################

<span style="color:DarkViolet">In this problem, you will use multiple linear regression to model the incomes of people from Wisconsin.</span>

<span style="color:DarkViolet">Data file (on D2L): *Wisconsin_income.csv*  </span>

<span style="color:DarkViolet">Data dictionary (on D2L): *Wisconsin_income data dictionary.txt*</span>

<span style="color:DarkViolet">Public Use Microdata from American Community Survey.  Accessed from http://www2.census.gov/programs-surveys/acs/data/pums/2014/1-Year/ on 27 July 2016.</span>
 

```{r echo=FALSE}
library(readr)
income = read_csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 3/Wisconsin_income.csv")
```

<span style="color:DarkViolet"></span>


### <span style="color:DarkViolet">Question 1</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Read in the data Wisconsin_income.csv.  Open the data dictionary in a text editor.  

<span style="color:DarkViolet">Notice that the following 9 variables are categorical, but are coded as numbers:  </span>  

* Citizenship  
* Class of worker  
* Language spoken at home  
* Marital status  
* Sex  
* Disability  
* Race  
* Hispanic  

<span style="color:DarkViolet">Tell R to treat them as factors.  Enter your R code below.</span>


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
#Citizenship, Class of worker, Language spoken at home, Marital status, Sex, Disability, Race, Hispanic to factor variables.
income$CIT2 = as.factor(income$CIT2)
income$COW = as.factor(income$COW)
income$LANX = as.factor(income$LANX)
income$MAR = as.factor(income$MAR)
income$SEX = as.factor(income$SEX)
income$DIS = as.factor(income$DIS)
income$RAC = as.factor(income$RAC)
income$Hispanic = as.factor(income$Hispanic)
```

### <span style="color:DarkViolet">Question 2</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Make histograms of people’s total earnings, usual hours worked per week, and travel time to work.  Which of these 3 variables are likely to benefit from log-transformation?  Apply the transformation if appropriate, and enter your R code below.</span>


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
  #creating histograms to check distribution of variables
hist(income$PERNP, main = "Distribution of Incomes", xlab = "Income (in thousands $)")
hist(income$WKHP, main = "Distribution Hours worked per Week", xlab = "Hours")
hist(income$JWMNP, main = "Distribution Travel Time to Work", xlab = "Travel time (in minutes)")

#both incomes and travel times look to be right-skewed, so we will log transform them.
income$logPERNP = log(income$PERNP)
income$logJWMNP = log(income$JWMNP)
```

### <span style="color:DarkViolet">Question 3</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Use *regsubsets()* to perform best subset selection for a linear model for total earnings as a function of all other variables in the data set.  
If you log-transformed any variables in the previous question, use the **transformed** variables, <span style="color:red"> *not* </span> the original variables, here.  Consider models with up to 41 variables.  Make a plot summarizing which variables are included in the best model of each size.  Enter your R code below.</span>


<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
library(leaps)

  #fit the best subsets regression. 
regfit.full = regsubsets(logPERNP~.-PERNP-JWMNP,data = income, nvmax = 41)
  #plot to find the variables that provide the lowest BIC
plot(regfit.full)
```

***

### <span style="color:DarkViolet">Question 4</span> **<span style="color:Crimson">(3 points)</span>**
<span style="color:DarkViolet">Plot adjusted $R^2$ as a function of number of variables.  Find the number of variables in the best model, as measured by adjusted $R^2$.  Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 4

#plotting the all subsets using the adj. r2 measure
plot(regfit.full, scale = "adjr2")

  #put the all subsets into a summary object
regfit.summary = summary(regfit.full)

  #pull the model with the max adjr2
which.max(regfit.summary$adjr2)
  #check the coefficients on model 35
coef(regfit.full,35)



  #pull the model with the min BIC
which.min(regfit.summary$bic)
  #check the coefficients on model 18
coef(regfit.full,18)
```

### <span style="color:DarkViolet">Question 5</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">How many variables (not counting the intercept) are in the best model, as measured by adjusted $R^2$?</span>

35, but -1 for intercept? Yes, so 34

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

### <span style="color:DarkViolet">Question 6</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">How many variables (not counting the intercept) are in the best model, as measured by BIC?</span>

18, but -1 for intercept? Yes, so 17

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

***

### <span style="color:DarkViolet">Question 7</span> **<span style="color:Crimson">(4 points)</span>**
<span style="color:DarkViolet">Set the random seed equal to 3:

```{r, echo=TRUE}
set.seed(3, sample.kind = "Rounding")
```
Perform 10-fold cross-validation to choose the best size of model (from 1 to 41 variables) based on cross-validation MSE.  Record the mean squared error within each fold for each size of variable.  **Note**: This step will probably take a few minutes to run!  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}

# Define a predict() function for regsubsets objects
predict.regsubsets <- function(object, newdata, id, ...){
	form = as.formula(object$call[[2]])
	mat = model.matrix(form, newdata)
	coefi = coef(object, id=id)
	xvars = names(coefi)
	mat[ , xvars] %*% coefi
} # end function predict.regsubsets



  #setting n to be the number of observations in the dataset
n = nrow(income)
  #using 10-fold cross-validation
k = 10 

  #produces list of group labels from 1-10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))  
  #setting up our cross-validation groups be randomizing each observation's CV group's label
cvgroups = sample(groups,n) 

  #row = number of variables per each model, column = which fold. This matrix will store each model's (from 1 to 41) CV error
group.error = matrix(,nr=41, nc=k) 

  #setting up a for loop to perform cross-validation
for(i in 1:k){
    #using the current iteration of the CV fold, set up a "test" hold out sample.
  test = (cvgroups == i)
	
    #perform all subsets regression, using all the data EXCEPT the test hold out sample, allow 41 variables. 
	cv.fit = regsubsets(logPERNP~.-PERNP-JWMNP, data=income[!test,], nvmax=41)
	
	  #now for each one of these 41 models, use the custom predict function on the test hold-out sample. 
	  #calculate the CV error and store it into the group.error matrix for the current model (id=j).
	  #repeat this process for all folds of the cross validation. 
	for(j in 1:41){
	    #use custom predict function - pass reg subsets object, the hold out dataset, and the current model (j).
		y.pred = predict.regsubsets(cv.fit, newdata = income[test,], id=j)
		  #calculate the CV error and store it in the appropate spot of the matrix
		group.error[j, i] = mean((income$logPERNP[test]-y.pred)^2)
	}
}

# Question 8

  #now that we have all the CV errors calculated for each of the 10 folds for all 41 models, we can average them up.
  #apply the mean function to each row (i.e. "1") of the group.error matrix
MSE = apply(group.error,1,mean)
  #plot this resulting vector to visualize the low point
plot(MSE)
  #or, just find the index of the row with the lowest MSE. That is our resulting model for selection. 
which.min(MSE)

```

### <span style="color:DarkViolet">Question 8</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">Find the mean of the MSEs from all the folds with the same number of variables.  Which number of variables gives the lowest cross-validation MSE?</span>

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

### <span style="color:DarkViolet">Question 9</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Estimate the standard error of the cross-validation errors and find the most parsimonious model with a CV error within 1 standard error of the lowest.  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 9

#in this exercise we want to use the "1-standard error rule" to determine the most parsimonious model that's acceptable.
#we will find the standard error's of each of the 41 models. 
#Then any models "within" 1-SE of the model that was identified above with the lowest MSE, can be considered comparable.
#the model with the lowest number of terms that result within 1-SE will be selected as the most parsimonious.

  #to find the standard error of each model, first apply standard deviation function to each row (i.e. "1") of the group.error
  #then divide by square root of k.
standard.error = apply(group.error,1,sd)/sqrt(k)

  #because model x had the best MSE, we'll take its MSE value and add one standard error onto it. 
  #Any of the models who's MSE is lower or equal to this is considered acceptable. We can choose the lowest model. 
which(MSE <= MSE[x]+standard.error[x])



  #check the coefficients on model x, there are p variables in use
coef(regfit.full,x)
```

***

### <span style="color:DarkViolet">Question 10</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">How many variables (not counting the intercept) are in the most parsimonious model with a CV error within 1 standard error of the lowest?</span>

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**: 

### <span style="color:DarkViolet">Question 11</span> **<span style="color:Crimson">(4 points)</span>**
<span style="color:DarkViolet">Use $\texttt{regsubsets}$ to find the best model for the whole data set which has the number of variables you found in the previous question.  Write 4-6 sentences interpreting the signs of the coefficients.  Include possible explanations for the associations.  **Note**: It may be helpful to refer to the data dictionary and/or a map of Wisconsin, such as https://en.wikipedia.org/wiki/Wisconsin#/media/File:Wisconsin-counties-map.gif.  Refer to variables in plain English. </span>

<span style="color:green">**Text Answer**: </span>
.  
.  
.  
.  
.  

***



#####################################################
## <span style="color:DarkViolet">Problem 2:  Logistic Regression  </span>
#####################################################

<span style="color:DarkViolet">In this problem, you will use logistic regression to predict whether a car has low or high gas mileage.</span>

### <span style="color:DarkViolet">Question 12</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Write R code to:  </span>

* Load the **Auto** data set into R.  The data set is in the ISLR library.  
* Create a binary variable that equals 1 for cars with gas mileage above the median and a 0 for cars with gas mileage below the median.  Tell R to treat it as a factor.  
* Tell R to treat the origin variable as a factor.  

<span style="color:DarkViolet">Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 12
  #load the dataset
library(ISLR)
data(Auto)

  #create a new variable called "highMPG". Set to 1 if the current observation's mpg is greater than the median of all mpgs. Treat as factor.
Auto$highMPG = as.factor(ifelse(Auto$mpg > median(Auto$mpg),"1","0"))


plot(Auto)
```

### <span style="color:DarkViolet">Question 13</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Make a matrix of scatterplots of the variables in **Auto**.  Do you have any concerns about collinearity?  If so, for which variables?  Explain.</span>

<span style="color:green">**Text Answer**: </span>

Yes I do see some issues with collinearity between variables, most of the variables that are regarding a car's engine appear to be correlated together: mpg, cylinders, displacement, horsepower, weight, acceleration. Even the year seems correlated with the mpg (which would make sense as technology improves).


***

### <span style="color:DarkViolet">Question 14</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Perform logistic regression of mpg.bin on the other variables in **Auto** (excluding mpg and name).  Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 14
  #fitting a logistic regression model with the response of my new "highMPG" variable, using all the data except mpg and name.
fit = glm(highMPG~.-mpg-name,data = Auto, family = "binomial")

# Question 15
  #loading the car package
library(car)
  #calculating vif scores on the variables within my models. none appear to be above 10. 
vif(fit)
```


### <span style="color:DarkViolet">Question 15</span> **<span style="color:Crimson">(1 points)</span>**
<span style="color:DarkViolet">Compute the variance inflation factor for each of the predictor variables in the model.  Which variable(s) have VIFs greater than or equal to 10?</span>

<span style="color:green">**Multiple SELECT Answer** </span>
**<span style="color:red">(AUTOGRADED on D2L)</span>**:  
cylinders,  

	
displacement,  

	
horsepower, and/or

	
weight

### <span style="color:DarkViolet">Question 16</span> **<span style="color:Crimson">(4 points)</span>**
<span style="color:DarkViolet">Remove any variables with VIFs greater than or equal to 10.  Set the random seed equal to 3:

```{r, echo=TRUE}
set.seed(3, sample.kind = "Rounding")
```
and perform 10-fold cross-validation.  In each phase of the cross-validation, fit the logistic model (excluding name, continuous mpg, and the variable(s) you found in the previous question and predict the probability of high gas mileage for each data point in the validation set.  Store all of the probabilities in a single vector.  
**Note**:  Depending on how you set up the formula in the logistic regression, the predict function may give an error, “Factor name has new levels.”  This is complaining about the fact that there are models of car in the validation set that weren’t included in the training data.  But, it’s not really a problem, because we’re not using name as a predictor variable.  You can create a new data frame that excludes name, or you can update the levels of the name factor in the logistic model, as shown here: http://stackoverflow.com/questions/22315394/factor-has-new-levels-error-for-variable-im-not-using  
Enter your R code below.</span>

<span style="color:green">**Code Answer**: </span>
```{r, echo=TRUE}
# Question 16

  #dropping the "names" variable from the dataset since it causes issues per the above note. 
Auto2 = Auto[,c(1:8,10)]
  #setting n to be the number of observations in the dataset
n = nrow(Auto2)
  #using 10-fold cross-validation
k = 10 

  #produces list of group labels from 1-10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))  
  #setting up our cross-validation groups be randomizing each observation's CV group's label
cvgroups = sample(groups,n) 

  #initializing an empty vector to store the CV error. set to -1 by default for easier troubleshooting.
predictvals = rep(-1,n)

  #setting up a for loop to perform cross-validation
for(i in 1:k){
    #using the current iteration of the CV fold, set up a "test" hold out sample.
  test = (cvgroups == i)
    #perform logistic regression, using all the data EXCEPT the test hold out sample. 
	fit = glm(highMPG~.-mpg,data = Auto2[!test,], family = "binomial")
	  #now, using the hold-out sample, retrieve predicted probabilities (type=response)
	predictvals[test] = predict(fit, Auto2[test,], type = "response")   
}

```


***

### <span style="color:DarkViolet">Question 17</span> **<span style="color:Crimson">(2 points)</span>**
<span style="color:DarkViolet">Create a ROC curve for this model.  What is its AUC?</span>

<span style="color:green">**Numeric Answer**  </span> **<span style="color:red">(AUTOGRADED on D2L)</span>**:  

```{r}
#Question 17
  #load the pROC library
library(pROC)
  #creating the roc object.
myroc = roc(response = Auto2$highMPG, predictor = predictvals)
  #calculating the AUC. 0.9679 in this case.
auc(myroc)
```


### <span style="color:DarkViolet">Question 18</span> **<span style="color:Crimson">(3 points)</span>**
<span style="color:DarkViolet">Upload an image of your ROC curve to *Homework 3: ROC Curve* (discussion board on D2L).  As part of your discussion post, write 1-2 sentences assessing the model based on the ROC curve and AUC.</span>

<span style="color:green">**Text Answer**: </span>

<span style="color:green">**Graph Answer**  </span>: 
```{r}
# Question 18
  #plotting the roc object to visualize the ROC curve
plot(myroc)


#The model has a good amount of area under the curve, thus performing much better than "random guessing". The curve jumps up sharply right away in sensitivity (or its ability to predict true positives), for a slight trade-off in 1-specificity (or the false positive rate). Overall, the model does a good job at predicting when cars have a high or low mpg, and at the same time not causing too many errors on false positives.

plot(myroc$thresholds,myroc$sensitivities,type="l",col="red")
lines(myroc$thresholds,myroc$specificities,col="green")

```



