knitr::opts_chunk$set(echo = TRUE)
churn = read.csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 13 - Final/Churn.csv")
churn = churn[,-c(1,2,3)]
churn$HasCrCard = as.factor(churn$HasCrCard)
churn$IsActiveMember = as.factor(churn$IsActiveMember)
churn$Exited = as.factor(churn$Exited)
summary(churn)
library(ggformula); library(ggpubr)
histo = ggarrange(ncol = 2, nrow = 3,
gf_histogram(~EstimatedSalary, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Balance, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~CreditScore, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Age, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Tenure,data = churn, color= ~Exited, fill = ~Exited),
gf_histogram(~NumOfProducts,data = churn, color= ~Exited, fill = ~Exited))
scatter = ggarrange(ncol = 2, nrow = 3,
gf_point(EstimatedSalary~Balance, data = churn, color = ~Exited),
gf_point(EstimatedSalary~CreditScore, data = churn, color = ~Exited),
gf_point(EstimatedSalary~Age, data = churn, color = ~Exited),
gf_point(EstimatedSalary~Tenure, data = churn, color = ~Exited),
gf_point(EstimatedSalary~NumOfProducts, data = churn, color = ~Exited))
boxplt = ggarrange(ncol = 2, nrow = 3,
gf_boxplot(EstimatedSalary~Exited, data = churn, color = ~Exited),
gf_boxplot(Balance~Exited, data = churn, color = ~Exited),
gf_boxplot(CreditScore~Exited, data = churn, color = ~Exited),
gf_boxplot(Age~Exited, data = churn, color = ~Exited),
gf_boxplot(Tenure~Exited, data = churn, color = ~Exited),
gf_boxplot(NumOfProducts~Exited, data = churn, color = ~Exited))
ggarrange(ncol = 2, nrow = 2, histo,scatter, boxplt)
churn$Age = log(churn$Age)
(cor(churn[,c(1,4,5,6,7,10)]))
n = nrow(churn)
k = 10
#set various threshold values to test best accuracy error.
threshold = seq(0.01,1, by = 0.01)
#randomize the data in 10 folds for CV10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
set.seed(10, sample.kind = "Rounding")
cvgroups = sample(groups,n)
n = nrow(churn)
k = 10
#set various threshold values to test best accuracy error.
threshold = seq(0.01,1, by = 0.01)
#randomize the data in 10 folds for CV10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
set.seed(13, sample.kind = "Rounding")
cvgroups = sample(groups,n)
library(nnet)
set.seed(13, sample.kind = "Rounding")
#setting decay rate and size tuning parameters.
decayRate = seq(.1, 1, by = .1)
size = seq(1,10, by = 1)
#create storage for error, 10x30 matrix.
nn.predProb = matrix( , nr = n, nc = (length(decayRate)*length(size)))
for(i in 1:k){
groupi = (cvgroups == i)
#scale numeric predictor variables for train
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
#calculate mean and sd of train set, stored separately to be used in scaling of validation set.
nn.train.means = apply(churn[!groupi,c(1,4,5,6,7,10)],2,mean)
nn.train.sd = apply(churn[!groupi,c(1,4,5,6,7,10)],2,sd)
#standardize the validation set using the means and sd's of the train set
nn.valid = cbind(churn[groupi,c(2,3,8,9,11)],
scale(churn[groupi,c(1,4,5,6,7,10)],
center = nn.train.means,
scale = nn.train.sd))
#set index for model number tracking
nn.index = 1
for(s in 1:length(size)){
for(d in 1:length(decayRate)){
#fit the model on the train data, and predict the validation data. Store in predprob matrix
nn.fit = nnet(Exited~., data=nn.train, size = size[s], decay = decayRate[d], maxit = 1000, trace = F)
nn.predProb[groupi, nn.index] = predict(nn.fit, nn.valid)
nn.index = nn.index + 1
}
}
}
library(pROC)
#setup storage matrix to calculate accuracies at various thresholds, for each of the 100 ANN models.
nn.model.acc = matrix(,nr = (length(decayRate)*length(size)), nc = length(threshold))
#loop for threshold values (columns)
for (t in 1:length(threshold)){
#set predicted class based on current threshold value
nn.predclass = ifelse(nn.predProb>threshold[t],1,0)
#loop for model number (rows)
for (m in 1:(length(size)*length(decayRate))){
#calculate accuracy for each threshold value and model.
nn.confusion = table(nn.predclass[,m],churn$Exited)
nn.model.acc[m,t] = sum(diag(nn.confusion))/sum(nn.confusion)
}
}
#Best model: 81 (size 8, decay 0.1), with threshold at 0.58. accuracy = 86.62%. set.seed(10)
which(nn.model.acc == max(nn.model.acc), arr.ind = T); max(nn.model.acc);
#For the best model, plot the accuracy as a function of threshold. Identify best accuracy with red point.
plot(threshold,
nn.model.acc[which(nn.model.acc == max(nn.model.acc), arr.ind = T)[1],],
type = "l",
main = "Neural Network Model Accuracy",xlab = "Threshold Values", ylab = "Accuracy")
points((which(nn.model.acc == max(nn.model.acc), arr.ind = T)[2]/100),max(nn.model.acc),pch = 8,col = "red")
#we also plot a roc curve, and calculate the AUC.
plot.roc(roc(response=churn$Exited,nn.predProb), print.auc = T)
#Best model: 81 (size 8, decay 0.1), with threshold at 0.58. accuracy = 86.62%. set.seed(10)
which(nn.model.acc == max(nn.model.acc), arr.ind = T); max(nn.model.acc);
View(nn.model.acc)
plot.roc(roc(response=churn$Exited,nn.predProb[92,]), print.auc = T)
View(nn.predProb)
plot.roc(roc(response=churn$Exited,nn.predProb[,92]), print.auc = T)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
fit = nnet(Exited~., data=churn.std, size = 9, decay = 0.2, maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance.
library(NeuralNetTools)
olden(fit)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
best.nn.fit = nnet(Exited~., data=churn.std, size = 9, decay = 0.2, maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance.
library(NeuralNetTools)
olden(best.nn.fit)
library(pROC)
#setup storage matrix to calculate accuracies at various thresholds, for each of the 100 ANN models.
nn.model.acc = matrix(,nr = (length(decayRate)*length(size)), nc = length(threshold))
#loop for threshold values (columns)
for (t in 1:length(threshold)){
#set predicted class based on current threshold value
nn.predclass = ifelse(nn.predProb>threshold[t],1,0)
#loop for model number (rows)
for (m in 1:(length(size)*length(decayRate))){
#calculate accuracy for each threshold value and model.
nn.confusion = table(nn.predclass[,m],churn$Exited)
nn.model.acc[m,t] = sum(diag(nn.confusion))/sum(nn.confusion)
}
}
#Best model: 92 (size 9, decay 0.2), with threshold at 0.57. accuracy = 86.71%. set.seed(13)
which(nn.model.acc == max(nn.model.acc), arr.ind = T); max(nn.model.acc);
#For the best model, plot the accuracy as a function of threshold. Identify best accuracy with red point.
plot(threshold,
nn.model.acc[which(nn.model.acc == max(nn.model.acc), arr.ind = T)[1],],
type = "l",
main = "Neural Network Model Accuracy",xlab = "Threshold Values", ylab = "Accuracy")
points((which(nn.model.acc == max(nn.model.acc), arr.ind = T)[2]/100),max(nn.model.acc),pch = 8,col = "red")
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,92]), print.auc = T)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
best.nn.fit = nnet(Exited~., data=churn.std, size = 9, decay = 0.2, maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance.
library(NeuralNetTools)
olden(best.nn.fit)
#this code was selected and modified from the online article:
#http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/
library(tidyverse)
library(broom)
#1: checking that continuous variables are linear to the logit of the response.
#full model fit to generate logit values
fullfit = glm(Exited~., data = churn, family = "binomial")
probabilities = predict(fullfit, type = "response")
predicted.classes = ifelse(probabilities>0.5,1,0)
#only check continuous variables
mydata = churn[,c(1,4,5,6,7,10)]
#build a stacked dataframe with the logit calculation as a column.
mydata = mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
#build the scatterplot and display a loess line to check for linearity.
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
#2: Check for influential outliers
#check points on a plot of cooks distance
plot(fullfit, which = 4, id.n = 3)
#plot residuals
model.data <- augment(fullfit) %>%
mutate(index = 1:n())
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = Exited), alpha = .5) +
theme_bw()
#check if any residuals are greater than 3 (none, so this checks)
model.data %>%
filter(abs(.std.resid) > 3)
#3: Check for collinearity. None are above a score of 10.
library(car)
vif(fullfit)
#4: response is binary. OK.
library(bestglm)
#copy dataframe and name response variable as "y" for bestglm()
lr.churn = churn
lr.churn$y = lr.churn$Exited
lr.churn = lr.churn[,-c(11)]
#find and fit the best logistic regression model per AIC.
best.lr.fit = bestglm(Xy = lr.churn, family = binomial, IC = "AIC", method = "exhaustive")
summary(best.lr.fit$BestModel)
#create storage for predictions.
lr.predProb = rep(-1, n)
#using CV10, make predicted probabilities for each observation using "best" logistic model.
for(i in 1:k){
groupi = (cvgroups == i)
lr.fit = glm(Exited~.-HasCrCard-EstimatedSalary, data = churn[groupi,], family = "binomial")
lr.predProb[!groupi] = predict(lr.fit, churn[!groupi,], type = "response")
}
library(pROC)
#creating storage for accuracy calculations
lr.model.acc = rep(-1,length(threshold))
#for each threshold, calculate and store accuracy of model's predictions
for (t in 1:length(threshold)){
lr.confusion = table(ifelse(lr.predProb>threshold[t],1,0),churn$Exited)
lr.model.acc[t] = sum(diag(lr.confusion))/sum(lr.confusion)
}
#Plot the model's accuracy as a function of the threshold. Best accuracy of 80.95% at threshold 0.59.
plot(threshold,lr.model.acc,type = "l",
main = "Logistic Regression Model Accuracy",xlab = "Threshold Values", ylab = "Accuracy")
points(which.max(lr.model.acc)/100,lr.model.acc[which.max(lr.model.acc)],pch = 8,col = "red")
#we also plot a roc curve for the best model.
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T)
install.packages("DMwR")
knitr::opts_chunk$set(echo = TRUE)
churn = read.csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 13 - Final/Churn.csv")
churn$HasCrCard = as.factor(churn$HasCrCard)
churn$IsActiveMember = as.factor(churn$IsActiveMember)
churn$Exited = as.factor(churn$Exited)
summary(churn)
churn$Age = log(churn$Age)
n = nrow(churn)
k = 10
#set various threshold values to test best accuracy error.
threshold = seq(0.01,1, by = 0.01)
#randomize the data in 10 folds for CV10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
set.seed(13, sample.kind = "Rounding")
cvgroups = sample(groups,n)
i=1
library(nnet)
set.seed(13, sample.kind = "Rounding")
#setting decay rate and size tuning parameters.
decayRate = seq(.1, 1, by = .1)
size = seq(1,10, by = 1)
#create storage for error, 10x30 matrix.
nn.predProb = matrix( , nr = n, nc = (length(decayRate)*length(size)))
groupi = (cvgroups == i)
#scale numeric predictor variables for train
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
groups
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
churn[!groupi,c(2,3,8,9,11)]
churn[!groupi,c(2,3,8,9,11)]
churn = read.csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 13 - Final/Churn.csv")
churn = churn[,-c(1,2,3)]
churn$HasCrCard = as.factor(churn$HasCrCard)
churn$IsActiveMember = as.factor(churn$IsActiveMember)
churn$Exited = as.factor(churn$Exited)
summary(churn)
churn$Age = log(churn$Age)
n = nrow(churn)
k = 10
#set various threshold values to test best accuracy error.
threshold = seq(0.01,1, by = 0.01)
#randomize the data in 10 folds for CV10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
set.seed(13, sample.kind = "Rounding")
cvgroups = sample(groups,n)
i=1
library(nnet)
set.seed(13, sample.kind = "Rounding")
#setting decay rate and size tuning parameters.
decayRate = seq(.1, 1, by = .1)
size = seq(1,10, by = 1)
#create storage for error, 10x30 matrix.
nn.predProb = matrix( , nr = n, nc = (length(decayRate)*length(size)))
groupi = (cvgroups == i)
#scale numeric predictor variables for train
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
#calculate mean and sd of train set, stored separately to be used in scaling of validation set.
nn.train.means = apply(churn[!groupi,c(1,4,5,6,7,10)],2,mean)
nn.train.sd = apply(churn[!groupi,c(1,4,5,6,7,10)],2,sd)
#standardize the validation set using the means and sd's of the train set
nn.valid = cbind(churn[groupi,c(2,3,8,9,11)],
scale(churn[groupi,c(1,4,5,6,7,10)],
center = nn.train.means,
scale = nn.train.sd))
summary(nn.train)
library(DMwR)
nn.train.SMOTE = SMOTE(Exited~., data = nn.train, perc.over = 200, perc.under = 150, k=5)
View(nn.train.SMOTE)
summary(nn.train.SMOTE)
library(nnet); library(DMwR)
set.seed(13, sample.kind = "Rounding")
#setting decay rate and size tuning parameters.
decayRate = seq(.1, 1, by = .1)
size = seq(1,10, by = 1)
#create storage for error, 10x30 matrix.
nn.predProb = matrix( , nr = n, nc = (length(decayRate)*length(size)))
for(i in 1:k){
groupi = (cvgroups == i)
#scale numeric predictor variables for train
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
#calculate mean and sd of train set, stored separately to be used in scaling of validation set.
nn.train.means = apply(churn[!groupi,c(1,4,5,6,7,10)],2,mean)
nn.train.sd = apply(churn[!groupi,c(1,4,5,6,7,10)],2,sd)
nn.train.SMOTE = SMOTE(Exited~., data = nn.train, perc.over = 200, perc.under = 150, k=5)
#standardize the validation set using the means and sd's of the train set
nn.valid = cbind(churn[groupi,c(2,3,8,9,11)],
scale(churn[groupi,c(1,4,5,6,7,10)],
center = nn.train.means,
scale = nn.train.sd))
#set index for model number tracking
nn.index = 1
for(s in 1:length(size)){
for(d in 1:length(decayRate)){
#fit the model on the train data, and predict the validation data. Store in predprob matrix
nn.fit = nnet(Exited~., data=nn.train, size = size[s], decay = decayRate[d], maxit = 1000, trace = F)
nn.predProb[groupi, nn.index] = predict(nn.fit, nn.valid)
nn.index = nn.index + 1
}
}
}
library(pROC)
#setup storage matrix to calculate accuracies at various thresholds, for each of the 100 ANN models.
nn.model.acc = matrix(,nr = (length(decayRate)*length(size)), nc = length(threshold))
#loop for threshold values (columns)
for (t in 1:length(threshold)){
#set predicted class based on current threshold value
nn.predclass = ifelse(nn.predProb>threshold[t],1,0)
#loop for model number (rows)
for (m in 1:(length(size)*length(decayRate))){
#calculate accuracy for each threshold value and model.
nn.confusion = table(nn.predclass[,m],churn$Exited)
nn.model.acc[m,t] = sum(diag(nn.confusion))/sum(nn.confusion)
}
}
#Best model: 92 (size 9, decay 0.2), with threshold at 0.57. accuracy = 86.71%. set.seed(13)
which(nn.model.acc == max(nn.model.acc), arr.ind = T); max(nn.model.acc);
#For the best model, plot the accuracy as a function of threshold. Identify best accuracy with red point.
plot(threshold,
nn.model.acc[which(nn.model.acc == max(nn.model.acc), arr.ind = T)[1],],
type = "l",
main = "Neural Network Model Accuracy",xlab = "Threshold Values", ylab = "Accuracy")
points((which(nn.model.acc == max(nn.model.acc), arr.ind = T)[2]/100),max(nn.model.acc),pch = 8,col = "red")
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,92]), print.auc = T)
myroc = roc(response=churn$Exited,nn.predProb[,92])
myroc = roc(response=churn$Exited,nn.predProb[,92])
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc
roc(response=churn$Exited,nn.predProb[,92])$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])
myroc = auc(roc(response=churn$Exited,nn.predProb[,92]))
myroc = auc(roc(response=churn$Exited,nn.predProb[,92]))$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc
roc(response=churn$Exited,nn.predProb[,92])$auc
print(roc(response=churn$Exited,nn.predProb[,92])$auc)
myroc = roc(response=churn$Exited,nn.predProb[,92])
auc(myroc)
temp = auc(myroc)
temp = auc(myroc)$auc
temp = myroc$auc
temp = temp + 1
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,92]), print.auc = T)
nn.model.roc = matrix(,nr = (length(decayRate)*length(size)), nc = length(threshold))
nn.model.roc = rep(NA, 100)
nn.model.roc = rep(NA, (length(size)*length(decayRate)))
nn.model.roc = rep(NA, (length(size)*length(decayRate)))
for (m in 1:(length(size)*length(decayRate))){
nn.model.roc[m] = roc(response=churn$Exited,nn.predProb[,m])$auc
}
which(nn.model.roc == max(nn.model.roc), arr.ind = T); max(nn.model.roc);
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), print.auc = T)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
best.nn.fit = nnet(Exited~., data=churn.std, size = 6, decay = 0.1, maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance.
library(NeuralNetTools)
olden(best.nn.fit)
library(bestglm)
#copy dataframe and name response variable as "y" for bestglm()
lr.churn = churn
lr.churn$y = lr.churn$Exited
lr.churn = lr.churn[,-c(11)]
#find and fit the best logistic regression model per AIC.
best.lr.fit = bestglm(Xy = lr.churn, family = binomial, IC = "AIC", method = "exhaustive")
summary(best.lr.fit$BestModel)
#create storage for predictions.
lr.predProb = rep(-1, n)
#using CV10, make predicted probabilities for each observation using "best" logistic model.
for(i in 1:k){
groupi = (cvgroups == i)
lr.fit = glm(Exited~.-HasCrCard-EstimatedSalary, data = churn[groupi,], family = "binomial")
lr.predProb[!groupi] = predict(lr.fit, churn[!groupi,], type = "response")
}
lr.model.roc = rep(NA, (length(size)*length(decayRate)))
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T)
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T, add = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), print.auc = T)
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T, add = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net", "Logistic"),
col=c(par("fg"), "blue"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net", "Logistic"),
col=c(par("green"), "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net", "Logistic"),
col=c("green", "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net AUC = 0.87", "Logistic"),
col=c("green", "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.87", "Logistic"),
col=c("green", "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.870", "Logistic: AUC = 0.760"),
col=c("green", "red"), lwd=2)
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.870", "Logistic: AUC = 0.767"),
col=c("green", "red"), lwd=2)
nn.confusion
