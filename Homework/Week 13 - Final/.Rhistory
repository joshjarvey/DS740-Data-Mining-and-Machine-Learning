groupi = (cvgroups == i)
#scale numeric predictor variables for train
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
#calculate mean and sd of train set, stored separately to be used in scaling of validation set.
nn.train.means = apply(churn[!groupi,c(1,4,5,6,7,10)],2,mean)
nn.train.sd = apply(churn[!groupi,c(1,4,5,6,7,10)],2,sd)
nn.train.SMOTE = SMOTE(Exited~., data = nn.train, perc.over = 200, perc.under = 150, k=5)
#standardize the validation set using the means and sd's of the train set
nn.valid = cbind(churn[groupi,c(2,3,8,9,11)],
scale(churn[groupi,c(1,4,5,6,7,10)],
center = nn.train.means,
scale = nn.train.sd))
#set index for model number tracking
nn.index = 1
for(s in 1:length(size)){
for(d in 1:length(decayRate)){
#fit the model on the train data, and predict the validation data. Store in predprob matrix
nn.fit = nnet(Exited~., data=nn.train, size = size[s], decay = decayRate[d], maxit = 1000, trace = F)
nn.predProb[groupi, nn.index] = predict(nn.fit, nn.valid)
nn.index = nn.index + 1
}
}
}
library(pROC)
#setup storage matrix to calculate accuracies at various thresholds, for each of the 100 ANN models.
nn.model.acc = matrix(,nr = (length(decayRate)*length(size)), nc = length(threshold))
#loop for threshold values (columns)
for (t in 1:length(threshold)){
#set predicted class based on current threshold value
nn.predclass = ifelse(nn.predProb>threshold[t],1,0)
#loop for model number (rows)
for (m in 1:(length(size)*length(decayRate))){
#calculate accuracy for each threshold value and model.
nn.confusion = table(nn.predclass[,m],churn$Exited)
nn.model.acc[m,t] = sum(diag(nn.confusion))/sum(nn.confusion)
}
}
#Best model: 92 (size 9, decay 0.2), with threshold at 0.57. accuracy = 86.71%. set.seed(13)
which(nn.model.acc == max(nn.model.acc), arr.ind = T); max(nn.model.acc);
#For the best model, plot the accuracy as a function of threshold. Identify best accuracy with red point.
plot(threshold,
nn.model.acc[which(nn.model.acc == max(nn.model.acc), arr.ind = T)[1],],
type = "l",
main = "Neural Network Model Accuracy",xlab = "Threshold Values", ylab = "Accuracy")
points((which(nn.model.acc == max(nn.model.acc), arr.ind = T)[2]/100),max(nn.model.acc),pch = 8,col = "red")
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,92]), print.auc = T)
myroc = roc(response=churn$Exited,nn.predProb[,92])
myroc = roc(response=churn$Exited,nn.predProb[,92])
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc
roc(response=churn$Exited,nn.predProb[,92])$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])
myroc = auc(roc(response=churn$Exited,nn.predProb[,92]))
myroc = auc(roc(response=churn$Exited,nn.predProb[,92]))$auc
myroc = roc(response=churn$Exited,nn.predProb[,92])$auc
roc(response=churn$Exited,nn.predProb[,92])$auc
print(roc(response=churn$Exited,nn.predProb[,92])$auc)
myroc = roc(response=churn$Exited,nn.predProb[,92])
auc(myroc)
temp = auc(myroc)
temp = auc(myroc)$auc
temp = myroc$auc
temp = temp + 1
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,92]), print.auc = T)
nn.model.roc = matrix(,nr = (length(decayRate)*length(size)), nc = length(threshold))
nn.model.roc = rep(NA, 100)
nn.model.roc = rep(NA, (length(size)*length(decayRate)))
nn.model.roc = rep(NA, (length(size)*length(decayRate)))
for (m in 1:(length(size)*length(decayRate))){
nn.model.roc[m] = roc(response=churn$Exited,nn.predProb[,m])$auc
}
which(nn.model.roc == max(nn.model.roc), arr.ind = T); max(nn.model.roc);
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), print.auc = T)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
best.nn.fit = nnet(Exited~., data=churn.std, size = 6, decay = 0.1, maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance.
library(NeuralNetTools)
olden(best.nn.fit)
library(bestglm)
#copy dataframe and name response variable as "y" for bestglm()
lr.churn = churn
lr.churn$y = lr.churn$Exited
lr.churn = lr.churn[,-c(11)]
#find and fit the best logistic regression model per AIC.
best.lr.fit = bestglm(Xy = lr.churn, family = binomial, IC = "AIC", method = "exhaustive")
summary(best.lr.fit$BestModel)
#create storage for predictions.
lr.predProb = rep(-1, n)
#using CV10, make predicted probabilities for each observation using "best" logistic model.
for(i in 1:k){
groupi = (cvgroups == i)
lr.fit = glm(Exited~.-HasCrCard-EstimatedSalary, data = churn[groupi,], family = "binomial")
lr.predProb[!groupi] = predict(lr.fit, churn[!groupi,], type = "response")
}
lr.model.roc = rep(NA, (length(size)*length(decayRate)))
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T)
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T, add = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), print.auc = T)
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T, add = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net", "Logistic"),
col=c(par("fg"), "blue"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net", "Logistic"),
col=c(par("green"), "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net", "Logistic"),
col=c("green", "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net AUC = 0.87", "Logistic"),
col=c("green", "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.87", "Logistic"),
col=c("green", "red"), lwd=2)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.870", "Logistic: AUC = 0.760"),
col=c("green", "red"), lwd=2)
plot.roc(roc(response=churn$Exited,lr.predProb), print.auc = T)
#we also plot a roc curve, and calculate the AUC = 0.867.
plot.roc(roc(response=churn$Exited,nn.predProb[,61]), col = "green")
plot.roc(roc(response=churn$Exited,lr.predProb), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.870", "Logistic: AUC = 0.767"),
col=c("green", "red"), lwd=2)
nn.confusion
knitr::opts_chunk$set(echo = TRUE)
churn = read.csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 13 - Final/Churn.csv")
churn = churn[,-c(1,2,3)]
churn$HasCrCard = as.factor(churn$HasCrCard)
churn$IsActiveMember = as.factor(churn$IsActiveMember)
churn$Exited = as.factor(churn$Exited)
summary(churn)
library(ggformula); library(ggpubr)
ggarrange(ncol = 2, nrow = 2,
#histograms
ggarrange(ncol = 2, nrow = 3,
gf_histogram(~EstimatedSalary, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Balance, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~CreditScore, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Age, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Tenure,data = churn, color= ~Exited, fill = ~Exited),
gf_histogram(~NumOfProducts,data = churn, color= ~Exited, fill = ~Exited)),
#scatterplots
ggarrange(ncol = 2, nrow = 3,
gf_point(EstimatedSalary~Balance, data = churn, color = ~Exited),
gf_point(EstimatedSalary~CreditScore, data = churn, color = ~Exited),
gf_point(EstimatedSalary~Age, data = churn, color = ~Exited),
gf_point(EstimatedSalary~Tenure, data = churn, color = ~Exited),
gf_point(EstimatedSalary~NumOfProducts, data = churn, color = ~Exited)),
#boxplots
ggarrange(ncol = 2, nrow = 3,
gf_boxplot(EstimatedSalary~Exited, data = churn, color = ~Exited),
gf_boxplot(Balance~Exited, data = churn, color = ~Exited),
gf_boxplot(CreditScore~Exited, data = churn, color = ~Exited),
gf_boxplot(Age~Exited, data = churn, color = ~Exited),
gf_boxplot(Tenure~Exited, data = churn, color = ~Exited),
gf_boxplot(NumOfProducts~Exited, data = churn, color = ~Exited)))
churn$Age = log(churn$Age)
library(nnet)
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
best.nn = 71
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
decayRate = seq(.1, 1, by = .1)
size = seq(1,10, by = 1)
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance/direction.
olden(nn.full.fit)
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance/direction.
olden(nn.full.fit)
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance/direction.
olden(nn.full.fit)
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance/direction.
olden(nn.full.fit)
knitr::opts_chunk$set(echo = TRUE)
churn = read.csv("C:/Users/joshj/Documents/DS740-Data Mining and Machine Learning/Homework/Week 13 - Final/Churn.csv")
churn = churn[,-c(1,2,3)]
churn$HasCrCard = as.factor(churn$HasCrCard)
churn$IsActiveMember = as.factor(churn$IsActiveMember)
churn$Exited = as.factor(churn$Exited)
summary(churn)
library(ggformula); library(ggpubr)
ggarrange(ncol = 2, nrow = 2,
#histograms
ggarrange(ncol = 2, nrow = 3,
gf_histogram(~EstimatedSalary, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Balance, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~CreditScore, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Age, data = churn, color = ~Exited, fill = ~Exited),
gf_histogram(~Tenure,data = churn, color= ~Exited, fill = ~Exited),
gf_histogram(~NumOfProducts,data = churn, color= ~Exited, fill = ~Exited)),
#scatterplots
ggarrange(ncol = 2, nrow = 3,
gf_point(EstimatedSalary~Balance, data = churn, color = ~Exited),
gf_point(EstimatedSalary~CreditScore, data = churn, color = ~Exited),
gf_point(EstimatedSalary~Age, data = churn, color = ~Exited),
gf_point(EstimatedSalary~Tenure, data = churn, color = ~Exited),
gf_point(EstimatedSalary~NumOfProducts, data = churn, color = ~Exited)),
#boxplots
ggarrange(ncol = 2, nrow = 3,
gf_boxplot(EstimatedSalary~Exited, data = churn, color = ~Exited),
gf_boxplot(Balance~Exited, data = churn, color = ~Exited),
gf_boxplot(CreditScore~Exited, data = churn, color = ~Exited),
gf_boxplot(Age~Exited, data = churn, color = ~Exited),
gf_boxplot(Tenure~Exited, data = churn, color = ~Exited),
gf_boxplot(NumOfProducts~Exited, data = churn, color = ~Exited)))
churn$Age = log(churn$Age)
cor(churn[,c(1,4,5,6,7,10)])
#set sample size and CV folds.
n = nrow(churn)
k = 10
#randomize the data into 10 folds for CV10
groups = c(rep(1:k,floor(n/k)),1:(n-floor(n/k)*k))
set.seed(13, sample.kind = "Rounding")
cvgroups = sample(groups,n)
library(nnet)
set.seed(13, sample.kind = "Rounding")
#setting decay rate and size tuning parameters.
decayRate = seq(.1, 1, by = .1)
size = seq(1,10, by = 1)
#create storage for predicted prob, 10,000x100 matrix.
nn.pred = matrix( , nr = n, nc = (length(decayRate)*length(size)))
#perform CV10 with SMOTE for balancing in test set.
for(i in 1:k){
groupi = (cvgroups == i)
#scale numeric predictor variables for train
nn.train = cbind(churn[!groupi,c(2,3,8,9,11)],
scale(churn[!groupi,c(1,4,5,6,7,10)]))
#calculate mean and sd of train set, stored separately to be used in scaling of validation set.
nn.train.means = apply(churn[!groupi,c(1,4,5,6,7,10)],2,mean)
nn.train.sd = apply(churn[!groupi,c(1,4,5,6,7,10)],2,sd)
#standardize the validation set using the means and sd's of the train set
nn.valid = cbind(churn[groupi,c(2,3,8,9,11)],
scale(churn[groupi,c(1,4,5,6,7,10)],
center = nn.train.means,
scale = nn.train.sd))
#set index for model number tracking
nn.index = 1
for(s in 1:length(size)){
for(d in 1:length(decayRate)){
#fit the model on the train data, and predict the validation data. Store in pred matrix
nn.fit = nnet(Exited~., data=nn.train, size = size[s], decay = decayRate[d], maxit = 1000, trace = F)
nn.pred[groupi, nn.index] = predict(nn.fit, nn.valid)
nn.index = nn.index + 1
}
}
}
library(pROC)
#create storage for AUC values.
nn.AUC = rep(NA, (length(size)*length(decayRate)))
#calculate AUC for each of the 100 models.
for (m in 1:(length(size)*length(decayRate))){
nn.AUC[m] = roc(response=churn$Exited,nn.pred[,m])$auc
}
#find the model number with the max AUC, and plot its ROC curve.
best.nn = which.max(nn.AUC)
plot.roc(roc(response=churn$Exited, nn.pred[,best.nn]), col = "green", main = "Neural Net - ROC Curve")
legend("bottomright", legend=c("Neural Net: AUC = 0.870"),
col=c("green"), lwd=2)
library(NeuralNetTools)
#scale the numeric predictors
churn.std = cbind(churn[,c(2,3,8,9,11)],scale(churn[,c(1,4,5,6,7,10)]))
#set the seed and fit the model using the best parameters
set.seed(13, sample.kind = "Rounding")
nn.full.fit = nnet(Exited~., data=churn.std,
size = floor((best.nn/length(size))),
decay = ((best.nn%%length(size)) + 1),
maxit = 1000, trace = F)
#plot the olden plot to get a sense of variable importance/direction.
olden(nn.full.fit)
#this code was selected and modified from the online article:
#http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/
library(tidyverse)
library(broom)
#1: checking that continuous variables are linear to the logit of the response.
#full model fit to generate logit values
fullfit = glm(Exited~., data = churn, family = "binomial")
probabilities = predict(fullfit, type = "response")
predicted.classes = ifelse(probabilities>0.5,1,0)
#only check continuous variables
mydata = churn[,c(1,4,5,6,7,10)]
#build a stacked dataframe with the logit calculation as a column.
mydata = mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
#build the scatterplot and display a loess line to check for linearity.
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
#2: Check for influential outliers
#check points on a plot of cooks distance
plot(fullfit, which = 4, id.n = 3)
#plot residuals
model.data <- augment(fullfit) %>%
mutate(index = 1:n())
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = Exited), alpha = .5) +
theme_bw()
#check if any residuals are greater than 3 (none, so this checks)
model.data %>%
filter(abs(.std.resid) > 3)
#3: Check for collinearity. None are above a score of 10.
library(car)
vif(fullfit)
#4: response is binary. OK.
library(bestglm)
#copy dataframe and name response variable as "y" for bestglm()
lr.churn = churn
lr.churn$y = lr.churn$Exited
lr.churn = lr.churn[,-c(11)]
#set up storage for predictions from CV10.
lr.pred = rep(NA,n)
#also setup storage to keep best model from each CV10 fold. We can inspect most common predictors as a way to gain some interpretability.
lr.model.selection = rep(NA,k)
#perform CV10 using bestglm().
for(i in 1:k){
groupi = (cvgroups == i)
lr.fit = bestglm(Xy = lr.churn[!groupi,], family = binomial, IC = "AIC", method = "exhaustive")
lr.model.selection[i] = lr.fit$BestModel
lr.pred[groupi] = predict(lr.fit$BestModel, churn[groupi,], type = "response")
}
#calculate AUC and plot the ROC curve.
lr.AUC = roc(response=churn$Exited, lr.pred)$auc
plot.roc(roc(response=churn$Exited, lr.pred), print.auc = T)
lr.model.selection
#compare best ROC curves from both the logistic regression and the neural network.
plot.roc(roc(response=churn$Exited,nn.pred[,61]), col = "green", main = "Neural Net vs. Logsitic Regression ROC Curve")
plot.roc(roc(response=churn$Exited,lr.pred), col = "red", add = T)
legend("bottomright", legend=c("Neural Net: AUC = 0.870", "Logistic: AUC = 0.771"),
col=c("green", "red"), lwd=2)
library(caret); library(nnet); library(pROC); library(bestglm)
#using the caret package to create train/valid splits.
set.seed(13, sample.kind = "Rounding")
trainsamples = createDataPartition(churn$Exited, p = 0.8, list = F, times = 1)
train.out = churn[trainsamples,]
valid.out = churn[-trainsamples,]
################################
## setting up inner CV10 loop ##
################################
#piping the training data into the inner process - 8001 observations.
fulldata.in = train.out
#setting inner sample size and CV.
n.in = nrow(train.out)
k.in = 10
#randomize the data into 10 sets for inner CV10.
groups.in = c(rep(1:k.in,floor(n.in/k.in)),1:(n.in-floor(n.in/k.in)*k.in))
cvgroups.in = sample(groups.in,n.in)
#copy dataframe and name response variable as "y" for bestglm().
lr.churn.in = fulldata.in
lr.churn.in$y = lr.churn.in$Exited
lr.churn.in = lr.churn.in[,-c(11)]
#setting up containers for predictions.
lr.pred.in = rep(NA,n.in)
nn.pred.in = matrix( , nr = n.in, nc = (length(decayRate)*length(size)))
##################################
## Complete inner CV10 process  ##
##################################
for(i in 1:k.in){
groupi.in = (cvgroups.in == i)
##############################################################
## Complete the bestglm() fit/predict for current iteration ##
##############################################################
lr.fit.in = bestglm(Xy = lr.churn.in[!groupi.in,], family = binomial, IC = "AIC", method = "exhaustive")
lr.pred.in[groupi.in] = predict(lr.fit.in$BestModel, lr.churn.in[groupi.in,], type = "response")
###############################################################
## Complete the neural net fit/predict for current iteration ##
###############################################################
#scale current training data.
nn.train.in = cbind(fulldata.in[!groupi.in,c(2,3,8,9,11)],
scale(fulldata.in[!groupi.in,c(1,4,5,6,7,10)]))
#calc mean/sd for current training data, to scale test data.
nn.train.means.in = apply(fulldata.in[!groupi.in,c(1,4,5,6,7,10)],2,mean)
nn.train.sd.in = apply(fulldata.in[!groupi.in,c(1,4,5,6,7,10)],2,sd)
#scale current testing data
nn.test.in = cbind(fulldata.in[groupi.in,c(2,3,8,9,11)],
scale(fulldata.in[groupi.in,c(1,4,5,6,7,10)],
center = nn.train.means.in,
scale = nn.train.sd.in))
#set index for model number tracking.
nn.index.in = 1
for(s in 1:length(size)){
for(d in 1:length(decayRate)){
#fit the model on the train data, and predict the test data. Store in pred matrix
nn.fit.in = nnet(Exited~., data=nn.train.in, size = size[s], decay = decayRate[d], maxit = 1000, trace = F)
nn.pred.in[groupi.in, nn.index.in] = predict(nn.fit.in, nn.test.in)
nn.index.in = nn.index.in + 1
}
}
}
#############################################
##      calculate AUC's from models        ##
#############################################
#calculate AUC for bestglm() method.
lr.AUC = roc(response = fulldata.in$Exited, lr.pred.in)$auc
#create storage for neural net's AUC values.
nn.AUC = rep(NA, (length(size)*length(decayRate)))
#calculate neural nets AUC values.
for (m in 1:(length(size)*length(decayRate))){
nn.AUC[m] = roc(response=fulldata.in$Exited,nn.pred.in[,m])$auc
}
#############################################################
##        Identify and use best model on validation set    ##
#############################################################
#combining AUC's, and selecting index of highest AUC - that is best model.
bestmodel = which.max(c(nn.AUC,lr.AUC))
#first - best model is a Neural Net. Else, best model is bestglm().
if(bestmodel <= length(nn.AUC)){
#scale full outer training data.
nn.train.out = cbind(train.out[,c(2,3,8,9,11)],
scale(train.out[,c(1,4,5,6,7,10)]))
#calc mean/sd for outer training data, to scale test data.
nn.train.means.out = apply(train.out[,c(1,4,5,6,7,10)],2,mean)
nn.train.sd.out = apply(train.out[,c(1,4,5,6,7,10)],2,sd)
#scale validation set based on train set values.
nn.valid.out = cbind(valid.out[,c(2,3,8,9,11)],
scale(valid.out[,c(1,4,5,6,7,10)],
center = nn.train.means.out,
scale = nn.train.sd.out))
#fit nn model with best model's size and decay rate.
best.fit = nnet(Exited~., data=nn.train.out,
size = floor((bestmodel/length(size))),
decay = ((bestmodel%%length(size)) + 1),
maxit = 1000, trace = F)
#make predictions on holdout set and plot the roc curve with honest AUC.
valid.pred = predict(best.fit,nn.valid.out)
plot.roc(roc(response=nn.valid.out$Exited,valid.pred), print.auc = T)
} else {
#prep the train data for bestglm().
lr.churn.out = train.out
lr.churn.out$y = lr.churn.out$Exited
lr.churn.out = lr.churn.out[,-c(11)]
#fit the bestglm()
best.fit = bestglm(Xy = lr.churn.out, family = binomial, IC = "AIC", method = "exhaustive")
#make predictions on holdout set and plot the roc curve with honest AUC.
valid.pred = predict(best.fit$BestModel, valid.out, type = "response")
plot.roc(roc(response=valid.out$Exited,valid.pred), print.auc = T)
}
